{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c8a98b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f72935",
   "metadata": {},
   "source": [
    "Week of September 29th, exploring python filters\n",
    "imported course catalog dataset\n",
    "\n",
    "Week of October 6th, exploring python filters\n",
    "delete unnecesary columns from main dataframe\n",
    "concatenate GPA dataset\n",
    "\n",
    "Week of October 13th, added RMP column cleaning to send to next teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c533df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datasets\n",
    "\n",
    "#import course catalog dataset\n",
    "df = pd.read_csv('2025-sp.csv') #df for data frame\n",
    "\n",
    "#import course GPA dataset\n",
    "df_GPA = pd.read_csv('uiuc-gpa-dataset.csv')\n",
    "\n",
    "#import teacher rating dataset\n",
    "df_Rate = pd.read_csv('uiuc-tre-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df45424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify name function modify_Name(str) to concat name to last name, first initial\n",
    "def modify_Name(name):\n",
    "    if not isinstance(name, str):\n",
    "        return name  # Handle non-string values\n",
    "    \n",
    "    parts = name.split(',')\n",
    "    last_name = parts[0].strip() # Get the last name\n",
    "    first_initial = parts[1].strip()[:1].upper()  # Get the first initial\n",
    "    return last_name + ', ' + first_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f61adc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df cleaning and modification (main)\n",
    "\n",
    "#delete unnecesary columns from main dataframe\n",
    "drop_cols = ['Term', 'Section Info','Schedule Information', 'Section Title', 'Enrollment Status','Status Code', 'Section Status', 'Section Credit Hours']\n",
    "df.drop(drop_cols, axis=1, inplace=True) \n",
    "df['Primary Instructor (Concat)'] = df['Instructors'].apply(lambda x: str(x).split(';')[0]) #add column for primary instructor\n",
    "df.rename(columns={'Type Code': 'Sched Type'}, inplace=True) #rename column to match GPA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c42c9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_GPA cleaning and modification\n",
    "# Chaging the last name to only first initial (to match main DF)\n",
    "df_GPA['Primary Instructor (Concat)'] = df_GPA['Primary Instructor'].apply(lambda name: modify_Name(name))\n",
    "\n",
    "# create mean_df_profBased_GPA + mean_df_classBased_GPA; mean GPA by professor for each class / only by class\n",
    "group_cols_wProf = ['Subject', 'Number', 'Sched Type', 'Primary Instructor', 'Primary Instructor (Concat)']\n",
    "group_cols = ['Subject', 'Number', 'Sched Type']\n",
    "merge_cols = ['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+','C', 'C-', 'D+', 'D', 'D-', 'F', 'W', 'Students']\n",
    "# by prof + class\n",
    "mean_df_profBased_GPA = df_GPA.groupby(group_cols_wProf, as_index = False)[merge_cols].mean().round(2)\n",
    "mean_df_profBased_GPA['Mean Grade By Professor (A+..F,W,Students)'] = mean_df_profBased_GPA[merge_cols].values.tolist()\n",
    "mean_df_profBased_GPA.drop(merge_cols, axis=1, inplace=True) \n",
    "# by only class\n",
    "mean_df_classBased_GPA = df_GPA.groupby(group_cols, as_index = False)[merge_cols].mean().round(2)\n",
    "mean_df_classBased_GPA['Mean Grade By Class (A+..F,W,Students)'] = mean_df_classBased_GPA[merge_cols].values.tolist()\n",
    "mean_df_classBased_GPA.drop(merge_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127f5ae4",
   "metadata": {},
   "source": [
    "Soft Preference Different Approaches:\n",
    "Right now, the issue with the merged dataset is that the df_GPA contains GPA information for the past 15 years, starting from 2010 to 2015.\n",
    "A couple possibilites here:\n",
    "    1. only take GPA data from the current year\n",
    "        - missing out on a lot of data here\n",
    "    2. take the most recent GPA\n",
    "        - again, missing out on data here \n",
    "        - (info could be provided in interface (i.e. data from 2022))\n",
    "    3. take the average of the GPA's for each professor (CURRENT APPROACH)\n",
    "        - changing class structure could be inacurate representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f4517d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Rate cleaning and modification\n",
    "\n",
    "#only consider data from past 10 years, drop role, term columns\n",
    "df_Rate['Year'] = df_Rate['term'].str.extract(r'(\\d{4})').astype(float) #extracts the year from term\n",
    "df_Rate = df_Rate[df_Rate['Year'] >= 2015] #only consider data from past 10 years (20 total bc 2 semesters per year)\n",
    "df_Rate.drop(columns=['Year', 'term', \"role\"], inplace=True)\n",
    "\n",
    "#seperate Excellent and Outstanding ratings into binary columns \n",
    "#DF TEAM SHOULD FIGURE OUT HOW EXCELLENT AND OUTSTANDING ARE RATED\n",
    "df_Rate['Excellent'] = df_Rate['ranking'].apply(lambda x: 1 if str(x) == 'Excellent' else 0)\n",
    "df_Rate['Outstanding'] = df_Rate['ranking'].apply(lambda x: 1 if str(x) == 'Outstanding' else 0)\n",
    "\n",
    "#merge lname and fname columns to match main df primary instructor concat column\n",
    "df_Rate['Primary Instructor (Concat)'] = df_Rate['lname'].str.title().str.strip() + ', ' + df_Rate['fname'].str.title().str.strip()\n",
    "\n",
    "#aggregate all excellent and outstanding with same unit, course number, and primary instructor (concat)\n",
    "df_Rate['Excellents'] = (df_Rate.groupby(['unit', 'course', 'Primary Instructor (Concat)'])['Excellent'].transform('sum'))\n",
    "df_Rate['Outstandings'] = (df_Rate.groupby(['unit', 'course', 'Primary Instructor (Concat)'])['Outstanding'].transform('sum'))\n",
    "\n",
    "#drop unnecessary columns before merge, rename columns to match main df\n",
    "df_Rate.drop(columns=['unit', 'lname', \"fname\", \"ranking\", \"Excellent\", \"Outstanding\"], inplace=True)\n",
    "df_Rate.rename(columns={'course': 'Number'}, inplace=True)\n",
    "\n",
    "#df_Rate was originally a String, convert to int to match main df, create NaN for \"???\"\n",
    "df_Rate['Number'] = pd.to_numeric(df_Rate['Number'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9160889",
   "metadata": {},
   "source": [
    "Rating Different Approaches:\n",
    "\n",
    "^^ rating also provides a tricky challenge - how do you define if the ranknig for a professor is good? does it count indefinitely after you get a ranking? or is it better to get more rankings? wouldnt that put teachers who are new at a disadvatange? is outstanding double as good as excellent? How do you quantify this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad155c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df merge w/ df_GPA + df_Rate\n",
    "group_cols_wProf = ['Subject', 'Number', 'Sched Type', 'Primary Instructor (Concat)'] # get rid of full name one bc OG df doesnt have that column\n",
    "df = df.merge(mean_df_profBased_GPA, how='left', on=group_cols_wProf)\n",
    "df = df.merge(mean_df_classBased_GPA, how='left', on=group_cols)\n",
    "df = df.merge(df_Rate, how='left', on=['Number', \"Primary Instructor (Concat)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f2af0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMP integration functions. full name search: getRMP(str) & fuzzy name search: getRMPfuzzy(str)\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "\n",
    "def getRMP(professor_full_name: str) -> float:\n",
    "  url = \"https://www.ratemyprofessors.com/search/professors/1112?q=\" + professor_full_name\n",
    "  \n",
    "  headers = {\n",
    "      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "  }\n",
    "  \n",
    "  try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "  except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error making request: {e}\")\n",
    "    return None\n",
    "\n",
    "  match = re.search(r'window\\.__RELAY_STORE__ = (.*?);', response.text)\n",
    "  if not match:\n",
    "    print(\"Could not find professor data on the page.\")\n",
    "    return None\n",
    "\n",
    "  try:\n",
    "    data = json.loads(match.group(1))\n",
    "  except json.JSONDecodeError:\n",
    "    print(\"Failed to parse JSON data.\")\n",
    "    return None\n",
    "\n",
    "  for key, value in data.items():\n",
    "    if isinstance(value, dict) and value.get('__typename') == 'Teacher':\n",
    "      first_name = value.get('firstName', '')\n",
    "      last_name = value.get('lastName', '')\n",
    "      \n",
    "      if f\"{first_name} {last_name}\".lower() == professor_full_name.lower():\n",
    "        avg_rating = value.get('avgRating')\n",
    "        if avg_rating is not None:\n",
    "          # Return the float value directly\n",
    "          return avg_rating\n",
    "          \n",
    "  return None\n",
    "\n",
    "def getRMPfuzzy(professor_full_name: str) -> float:\n",
    "  url = \"https://www.ratemyprofessors.com/search/professors/1112?q=\" + professor_full_name\n",
    "  \n",
    "  headers = {\n",
    "      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "  }\n",
    "  \n",
    "  try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "  except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error making request: {e}\")\n",
    "    return None\n",
    "\n",
    "  match = re.search(r'window\\.__RELAY_STORE__ = (.*?);', response.text)\n",
    "  if not match:\n",
    "    print(\"Could not find professor data on the page.\")\n",
    "    return None\n",
    "\n",
    "  try:\n",
    "    data = json.loads(match.group(1))\n",
    "  except json.JSONDecodeError:\n",
    "    print(\"Failed to parse JSON data.\")\n",
    "    return None\n",
    "\n",
    "  for key, value in data.items():\n",
    "    if isinstance(value, dict) and value.get('__typename') == 'Teacher':\n",
    "      avg_rating = value.get('avgRating')\n",
    "      if avg_rating is not None:\n",
    "          # Return the float value directly\n",
    "        return avg_rating\n",
    "          \n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to save the modified dataframe to a csv file, uncomment the following line (CSV already uploaded in google drive!)\n",
    "#df.to_csv('modified-2025-sp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a411d",
   "metadata": {},
   "source": [
    "DO NOT RUN THE FOLLOWING CODE UNLESS YOU WANT YOUR CODE TO RUN FOR AT LEAST 3 HOURS!\n",
    "*if you just want the csv, it is uploaded in the google drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "from tqdm import tqdm #need to type \"pip3 install tqdm\" in terminal if not installed\n",
    "import pandas as pd\n",
    "\n",
    "# cached functions to avoid repeated queries\n",
    "@lru_cache(maxsize=None)\n",
    "def cached_getRMP(name):\n",
    "    return getRMP(name)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def cached_getRMPfuzzy(name):\n",
    "    return getRMPfuzzy(name)\n",
    "\n",
    "# prepare an empty list to store results\n",
    "rmp_results = []\n",
    "\n",
    "chunk_size = 1000  # number of rows per chunk\n",
    "num_chunks = (len(df) + chunk_size - 1) // chunk_size  # total number of chunks\n",
    "\n",
    "for i in tqdm(range(num_chunks), desc=\"Processing RMP\"):\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = min((i+1) * chunk_size, len(df))\n",
    "    chunk = df.iloc[start_idx:end_idx]\n",
    "\n",
    "    # apply the function to the chunk\n",
    "    chunk_results = chunk.apply(\n",
    "        lambda row: (\n",
    "            cached_getRMP(str(row['Primary Instructor']).strip())\n",
    "            if pd.notna(row['Primary Instructor']) and str(row['Primary Instructor']).strip() != ''\n",
    "            else cached_getRMPfuzzy(str(row.get('Primary Instructor (Concat)', '')).strip())\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    rmp_results.extend(chunk_results)\n",
    "\n",
    "# assign results back to the DataFrame\n",
    "df['RMP'] = rmp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8cf314",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
